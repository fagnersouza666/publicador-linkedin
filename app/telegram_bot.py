#!/usr/bin/env python3
"""
Telegram Bot para receber arquivos HTML e iniciar pipeline de processamento
Sistema de produÃ§Ã£o com filas (pendentes â†’ enviados) e logs por data
"""
import os
import json
import logging
import asyncio
from datetime import datetime, time
from pathlib import Path
from typing import Optional, Dict, Tuple

from dotenv import load_dotenv
import requests
from telegram import Update, Document
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    filters,
    ContextTypes,
)

# Importar mÃ³dulos do projeto
from .post_processor import PostProcessor
from .html_parser import HTMLParser, validate_html_file
from .linkedin_poster import observability, logger
from .content_reviewer import ContentReviewer  # ğŸ†• Revisor de conteÃºdo

# Carregar configuraÃ§Ãµes
load_dotenv()

# ConfiguraÃ§Ãµes do bot
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")

# Sistema de filas em produÃ§Ã£o
POSTS_BASE_DIR = "posts"
POSTS_PENDENTES_DIR = os.path.join(POSTS_BASE_DIR, "pendentes")
POSTS_ENVIADOS_DIR = os.path.join(POSTS_BASE_DIR, "enviados")
POSTS_LOGS_DIR = os.path.join(POSTS_BASE_DIR, "logs")

# Configurar diretÃ³rios de produÃ§Ã£o
for directory in [
    POSTS_BASE_DIR,
    POSTS_PENDENTES_DIR,
    POSTS_ENVIADOS_DIR,
    POSTS_LOGS_DIR,
]:
    os.makedirs(directory, exist_ok=True)


class TelegramPipeline:
    """Gerenciador do pipeline Telegram â†’ GPT â†’ RevisÃ£o â†’ LinkedIn com sistema de filas de produÃ§Ã£o"""

    def __init__(self):
        self.processor = PostProcessor()
        self.html_parser = HTMLParser()
        self.reviewer = ContentReviewer()  # ğŸ†• Revisor
        self.authorized_users = self._get_authorized_users()
        self.setup_daily_logger()

        # ğŸ†• Sistema de aprovaÃ§Ã£o temporÃ¡ria
        self.pending_approvals = (
            {}
        )  # {user_id: {content, file_path, execution_id, etc}}

    def setup_daily_logger(self):
        """Configurar logger por data (YYYY-MM-DD.log)"""
        today = datetime.now().strftime("%Y-%m-%d")
        log_file = os.path.join(POSTS_LOGS_DIR, f"{today}.log")

        # Configurar handler especÃ­fico para o pipeline
        self.pipeline_logger = logging.getLogger(f"pipeline_{today}")
        self.pipeline_logger.setLevel(logging.INFO)

        # Evitar duplicaÃ§Ã£o de handlers
        if not self.pipeline_logger.handlers:
            handler = logging.FileHandler(log_file, encoding="utf-8")
            formatter = logging.Formatter(
                "%(asctime)s - %(levelname)s - %(message)s", datefmt="%H:%M:%S"
            )
            handler.setFormatter(formatter)
            self.pipeline_logger.addHandler(handler)

        self.pipeline_logger.info(f"ğŸ“… Pipeline iniciado - {today}")

    def _get_authorized_users(self) -> list:
        """Obter lista de usuÃ¡rios autorizados"""
        authorized = os.getenv("TELEGRAM_AUTHORIZED_USERS", "")
        if authorized:
            return [int(uid.strip()) for uid in authorized.split(",")]
        return []

    def is_authorized(self, user_id: int) -> bool:
        """Verificar se usuÃ¡rio estÃ¡ autorizado"""
        if not self.authorized_users:
            return True  # Se nÃ£o configurado, permite todos
        return user_id in self.authorized_users

    def validate_posting_time(self) -> Dict:
        """Validar se Ã© um horÃ¡rio apropriado para posting"""
        now = datetime.now()
        current_time = now.time()
        current_day = now.weekday()  # 0=segunda, 6=domingo

        validation = {"valid": True, "warnings": [], "recommendations": []}

        # HorÃ¡rios recomendados para LinkedIn (8h-18h dias Ãºteis)
        business_start = time(8, 0)  # 08:00
        business_end = time(18, 0)  # 18:00

        # Verificar se Ã© dia Ãºtil (segunda a sexta)
        if current_day >= 5:  # sÃ¡bado ou domingo
            validation["warnings"].append(
                f"ğŸ“… Final de semana - menor engajamento esperado"
            )
            validation["recommendations"].append(
                "Considere agendar para segunda-feira 8h-10h"
            )

        # Verificar horÃ¡rio
        if current_time < business_start:
            validation["warnings"].append(
                f"ğŸ• Muito cedo ({now.strftime('%H:%M')}) - audiÃªncia ainda nÃ£o ativa"
            )
            validation["recommendations"].append("HorÃ¡rio ideal: 8h-10h ou 17h-19h")
        elif current_time > business_end:
            validation["warnings"].append(
                f"ğŸ• HorÃ¡rio tardio ({now.strftime('%H:%M')}) - menor visibilidade"
            )
            validation["recommendations"].append(
                "Considere postar entre 8h-18h nos dias Ãºteis"
            )
        else:
            validation["recommendations"].append(
                f"âœ… Bom horÃ¡rio para posting ({now.strftime('%H:%M')})"
            )

        return validation

    def create_standardized_filename(
        self, document: Document, metadata: Dict
    ) -> Tuple[str, str]:
        """Criar nome de arquivo padronizado na fila de pendentes"""

        # Timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # Slug do tÃ­tulo
        title = metadata.get("title", "")
        if not title and document.file_name:
            # Usar nome do arquivo original como fallback
            title = Path(document.file_name).stem

        slug = self.html_parser.create_slug(title) if title else "sem_titulo"

        # Nome final padronizado na fila de pendentes
        filename = f"{timestamp}_{slug}.html"
        filepath = os.path.join(POSTS_PENDENTES_DIR, filename)

        # Garantir que nÃ£o existe conflito
        counter = 1
        while os.path.exists(filepath):
            filename = f"{timestamp}_{slug}_{counter}.html"
            filepath = os.path.join(POSTS_PENDENTES_DIR, filename)
            counter += 1

        return filepath, filename

    def save_metadata(
        self, filepath: str, metadata: Dict, document: Document, user_id: int
    ) -> str:
        """Salvar metadata.json junto com o arquivo HTML"""

        # Criar metadata expandido
        full_metadata = {
            **metadata,
            "telegram": {
                "user_id": user_id,
                "file_name": document.file_name,
                "file_size": document.file_size,
                "mime_type": document.mime_type,
                "received_at": datetime.now().isoformat(),
            },
            "processing": {
                "status": "pendente",
                "queue": "pendentes",
                "pipeline_id": None,
                "processed_at": None,
                "published_at": None,
                "moved_to_enviados_at": None,
            },
            "validation": {
                "html_valid": metadata.get("valid", False),
                "time_check": self.validate_posting_time(),
            },
            "production": {
                "daily_log": datetime.now().strftime("%Y-%m-%d.log"),
                "queue_position": self.get_queue_position(),
            },
        }

        # Caminho do metadata
        metadata_path = filepath.replace(".html", ".metadata.json")

        try:
            with open(metadata_path, "w", encoding="utf-8") as f:
                json.dump(full_metadata, f, indent=2, ensure_ascii=False)

            self.pipeline_logger.info(
                f"ğŸ“‹ Metadata salvo: {os.path.basename(metadata_path)}"
            )
            return metadata_path

        except Exception as e:
            self.pipeline_logger.error(f"âŒ Erro ao salvar metadata: {e}")
            return ""

    def get_queue_position(self) -> int:
        """Obter posiÃ§Ã£o atual na fila de pendentes"""
        try:
            files = [f for f in os.listdir(POSTS_PENDENTES_DIR) if f.endswith(".html")]
            return len(files) + 1
        except:
            return 1

    def move_to_enviados(
        self, pendente_path: str, metadata_path: str
    ) -> Tuple[str, str]:
        """Mover arquivo processado de pendentes para enviados"""
        try:
            filename = os.path.basename(pendente_path)
            metadata_filename = os.path.basename(metadata_path)

            # Caminhos de destino
            enviado_path = os.path.join(POSTS_ENVIADOS_DIR, filename)
            enviado_metadata_path = os.path.join(POSTS_ENVIADOS_DIR, metadata_filename)

            # Mover arquivos
            os.rename(pendente_path, enviado_path)

            # Atualizar metadata antes de mover
            if os.path.exists(metadata_path):
                with open(metadata_path, "r") as f:
                    meta = json.load(f)
                meta["processing"]["status"] = "enviado"
                meta["processing"]["queue"] = "enviados"
                meta["processing"]["moved_to_enviados_at"] = datetime.now().isoformat()

                with open(metadata_path, "w") as f:
                    json.dump(meta, f, indent=2)

                os.rename(metadata_path, enviado_metadata_path)

            self.pipeline_logger.info(f"ğŸ“¤ Movido para enviados: {filename}")
            return enviado_path, enviado_metadata_path

        except Exception as e:
            self.pipeline_logger.error(f"âŒ Erro ao mover para enviados: {e}")
            return pendente_path, metadata_path

    async def download_and_validate_file(
        self, document: Document, context: ContextTypes.DEFAULT_TYPE, user_id: int
    ) -> Optional[Dict]:
        """Baixar arquivo e fazer validaÃ§Ã£o completa na fila de pendentes"""
        try:
            # 1. Baixar arquivo temporÃ¡rio primeiro
            temp_path = f"{POSTS_PENDENTES_DIR}/temp_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"

            file = await document.get_file()
            await file.download_to_drive(temp_path)

            self.pipeline_logger.info(
                f"ğŸ“¥ Arquivo temporÃ¡rio baixado: {os.path.basename(temp_path)}"
            )

            # 2. Validar conteÃºdo HTML
            validation = validate_html_file(temp_path)

            if not validation["valid"]:
                # Remover arquivo temporÃ¡rio se invÃ¡lido
                os.remove(temp_path)
                self.pipeline_logger.warning(
                    f"âŒ Arquivo invÃ¡lido removido: {document.file_name}"
                )
                return {"status": "invalid", "validation": validation}

            # 3. Extrair metadados
            metadata = self.html_parser.extract_metadata(temp_path)
            metadata.update(validation)  # Incluir dados de validaÃ§Ã£o

            # 4. Criar nome de arquivo padronizado na fila
            final_path, filename = self.create_standardized_filename(document, metadata)

            # 5. Mover arquivo para nome final na fila de pendentes
            os.rename(temp_path, final_path)

            # 6. Salvar metadata.json
            metadata_path = self.save_metadata(final_path, metadata, document, user_id)

            queue_position = (
                self.get_queue_position() - 1
            )  # -1 porque jÃ¡ foi adicionado
            self.pipeline_logger.info(
                f"âœ… Arquivo na fila: {filename} (posiÃ§Ã£o {queue_position})"
            )

            return {
                "status": "success",
                "file_path": final_path,
                "filename": filename,
                "metadata_path": metadata_path,
                "metadata": metadata,
                "validation": validation,
                "queue_position": queue_position,
            }

        except Exception as e:
            # Limpar arquivo temporÃ¡rio se existir
            if "temp_path" in locals() and os.path.exists(temp_path):
                os.remove(temp_path)

            self.pipeline_logger.error(f"âŒ Erro ao processar arquivo: {e}")
            return {"status": "error", "error": str(e)}

    async def process_pipeline_with_review(
        self, file_path: str, user_id: int, metadata: Dict
    ) -> dict:
        """Executar pipeline com revisÃ£o prÃ©-publicaÃ§Ã£o"""
        execution_id = f"tg_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{user_id}"
        start_time = datetime.now()

        try:
            # Log inÃ­cio do pipeline
            self.pipeline_logger.info(
                f"ğŸš€ Pipeline com revisÃ£o iniciado: {execution_id}"
            )

            # 1. Atualizar metadata de status
            metadata_path = file_path.replace(".html", ".metadata.json")
            if os.path.exists(metadata_path):
                with open(metadata_path, "r") as f:
                    meta = json.load(f)
                meta["processing"]["status"] = "processando"
                meta["processing"]["pipeline_id"] = execution_id
                with open(metadata_path, "w") as f:
                    json.dump(meta, f, indent=2)

            # 2. Processar com GPT
            self.pipeline_logger.info("ğŸ¤– Processando conteÃºdo com GPT-4o-mini...")
            processed_content = await self.processor.process_html_file(file_path)

            if not processed_content:
                raise Exception("Falha no processamento GPT")

            processing_time = int((datetime.now() - start_time).total_seconds() * 1000)
            self.pipeline_logger.info(f"âœ… GPT processado em {processing_time}ms")

            # 3. ğŸ†• REVISÃƒO PRÃ‰-PUBLICAÃ‡ÃƒO
            self.pipeline_logger.info("ğŸ“‹ Iniciando revisÃ£o de conteÃºdo...")
            review = self.reviewer.review_content(
                processed_content, metadata.get("title", "")
            )

            # Salvar review
            review_path = self.reviewer.save_review(review, file_path)
            self.pipeline_logger.info(f"ğŸ“‹ Review salvo: {review_path}")

            # Atualizar metadata com review
            if os.path.exists(metadata_path):
                with open(metadata_path, "r") as f:
                    meta = json.load(f)
                meta["processing"]["status"] = "aguardando_aprovacao"
                meta["content_review"] = review
                meta["review_path"] = review_path
                with open(metadata_path, "w") as f:
                    json.dump(meta, f, indent=2)

            # 4. Armazenar para aprovaÃ§Ã£o
            self.pending_approvals[user_id] = {
                "execution_id": execution_id,
                "file_path": file_path,
                "metadata_path": metadata_path,
                "processed_content": processed_content,
                "review": review,
                "original_metadata": metadata,
                "created_at": datetime.now().isoformat(),
            }

            review_time = int((datetime.now() - start_time).total_seconds() * 1000)
            self.pipeline_logger.info(
                f"ğŸ“‹ RevisÃ£o completa em {review_time}ms - Aguardando aprovaÃ§Ã£o"
            )

            return {
                "status": "awaiting_approval",
                "execution_id": execution_id,
                "processed_content": processed_content,
                "review": review,
                "duration_ms": review_time,
                "title": metadata.get("title", "N/A"),
                "requires_approval": True,
            }

        except Exception as e:
            # Log erro no pipeline
            error_time = int((datetime.now() - start_time).total_seconds() * 1000)
            self.pipeline_logger.error(
                f"ğŸ’¥ Erro no pipeline com revisÃ£o {execution_id}: {e}"
            )

            # Atualizar metadata com erro
            metadata_path = file_path.replace(".html", ".metadata.json")
            if os.path.exists(metadata_path):
                with open(metadata_path, "r") as f:
                    meta = json.load(f)
                meta["processing"]["status"] = "erro"
                meta["processing"]["error"] = str(e)
                meta["processing"]["error_at"] = datetime.now().isoformat()
                with open(metadata_path, "w") as f:
                    json.dump(meta, f, indent=2)

            return {
                "status": "error",
                "execution_id": execution_id,
                "error": str(e),
                "duration_ms": error_time,
            }

    async def publish_approved_content(self, user_id: int) -> dict:
        """Publicar conteÃºdo aprovado pelo usuÃ¡rio"""
        if user_id not in self.pending_approvals:
            return {"status": "error", "error": "Nenhum conteÃºdo aguardando aprovaÃ§Ã£o"}

        approval_data = self.pending_approvals[user_id]
        execution_id = approval_data["execution_id"]
        processed_content = approval_data["processed_content"]
        file_path = approval_data["file_path"]
        metadata_path = approval_data["metadata_path"]

        start_time = datetime.now()

        try:
            # Atualizar status para publicando
            if os.path.exists(metadata_path):
                with open(metadata_path, "r") as f:
                    meta = json.load(f)
                meta["processing"]["status"] = "publicando"
                meta["processing"]["approved_at"] = start_time.isoformat()
                with open(metadata_path, "w") as f:
                    json.dump(meta, f, indent=2)

            # Publicar no LinkedIn
            self.pipeline_logger.info(
                f"ğŸ”— Publicando conteÃºdo aprovado: {execution_id}"
            )
            from .linkedin_poster import get_driver, login, publish_post

            driver = None
            try:
                driver = get_driver()
                login(driver, execution_id)
                publish_post(driver, processed_content, execution_id)

                # Mover para enviados apÃ³s sucesso
                enviado_path, enviado_metadata_path = self.move_to_enviados(
                    file_path, metadata_path
                )

                # Atualizar metadata final
                if os.path.exists(enviado_metadata_path):
                    with open(enviado_metadata_path, "r") as f:
                        meta = json.load(f)
                    meta["processing"]["status"] = "publicado"
                    meta["processing"]["published_at"] = datetime.now().isoformat()
                    meta["processing"]["final_content"] = processed_content
                    with open(enviado_metadata_path, "w") as f:
                        json.dump(meta, f, indent=2)

                # Limpar aprovaÃ§Ã£o pendente
                del self.pending_approvals[user_id]

                total_time = int((datetime.now() - start_time).total_seconds() * 1000)
                self.pipeline_logger.info(
                    f"ğŸ‰ PublicaÃ§Ã£o aprovada completa: {execution_id} em {total_time}ms"
                )

                return {
                    "status": "published",
                    "execution_id": execution_id,
                    "processed_content": processed_content,
                    "duration_ms": total_time,
                    "moved_to": "enviados",
                }

            finally:
                if driver:
                    driver.quit()

        except Exception as e:
            error_time = int((datetime.now() - start_time).total_seconds() * 1000)
            self.pipeline_logger.error(
                f"ğŸ’¥ Erro na publicaÃ§Ã£o aprovada {execution_id}: {e}"
            )

            # Manter em pendentes com erro, mas nÃ£o remover da aprovaÃ§Ã£o
            # O usuÃ¡rio pode tentar novamente
            return {
                "status": "error",
                "execution_id": execution_id,
                "error": str(e),
                "duration_ms": error_time,
            }


# InstÃ¢ncia global do pipeline
pipeline = TelegramPipeline()


async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Comando /start"""
    user_id = update.effective_user.id

    if not pipeline.is_authorized(user_id):
        await update.message.reply_text("âŒ UsuÃ¡rio nÃ£o autorizado")
        return

    # Verificar horÃ¡rio atual
    time_check = pipeline.validate_posting_time()
    time_info = ""
    if time_check["warnings"]:
        time_info = f"\nâš ï¸ {time_check['warnings'][0]}"
    if time_check["recommendations"]:
        time_info += f"\nğŸ’¡ {time_check['recommendations'][0]}"

    # Status da fila
    pendentes = len([f for f in os.listdir(POSTS_PENDENTES_DIR) if f.endswith(".html")])
    enviados = len([f for f in os.listdir(POSTS_ENVIADOS_DIR) if f.endswith(".html")])

    # Verificar se tem aprovaÃ§Ã£o pendente
    approval_status = ""
    if user_id in pipeline.pending_approvals:
        approval_status = (
            "\nğŸ”” **VOCÃŠ TEM CONTEÃšDO AGUARDANDO APROVAÃ‡ÃƒO** - Use /pending"
        )

    message = f"""
ğŸš€ **LinkedIn Content Pipeline Bot v2.6.1**

Envie um arquivo HTML e eu vou:
1. ğŸ“¥ Adicionar Ã  fila de **pendentes**
2. ğŸ“‹ Extrair metadados (tÃ­tulo, descriÃ§Ã£o, etc.)
3. ğŸ¤– Processar com GPT-4o-mini
4. ğŸ“‹ **REVISAR CONTEÃšDO** (sem alterar estilo)
5. â¸ï¸ **AGUARDAR SUA APROVAÃ‡ÃƒO**
6. ğŸ”— Publicar no LinkedIn (apÃ³s aprovaÃ§Ã£o)
7. ğŸ“¤ Mover para **enviados**
8. ğŸ’¾ Log diÃ¡rio: `{datetime.now().strftime('%Y-%m-%d.log')}`

**Sistema de Filas de ProduÃ§Ã£o:**
ğŸ“‚ Pendentes: {pendentes} arquivos
ğŸ“¤ Enviados: {enviados} arquivos
{approval_status}

**ğŸ” Sistema de RevisÃ£o:**
âœ… ValidaÃ§Ã£o de gramÃ¡tica/ortografia
âœ… VerificaÃ§Ã£o de compliance LinkedIn
âœ… AnÃ¡lise de tom profissional
âœ… **AprovaÃ§Ã£o manual obrigatÃ³ria**

**ğŸ“± Comandos principais:**
/start - Mostrar esta mensagem
/queue - Status da fila
/status - Ver status do sistema
/stats - EstatÃ­sticas de uso

**ğŸ“‹ Comandos de aprovaÃ§Ã£o:**
/pending - Ver conteÃºdo aguardando aprovaÃ§Ã£o
/approve - Aprovar e publicar
/cancel - Cancelar conteÃºdo
/retry - Tentar publicar novamente

**ValidaÃ§Ãµes automÃ¡ticas:**
âœ… ConteÃºdo HTML vÃ¡lido
âœ… Tamanho adequado (50+ chars)
âœ… Estrutura de arquivo padronizada
âœ… HorÃ¡rio de posting otimizado
{time_info}
"""

    await update.message.reply_text(message, parse_mode="Markdown")


async def queue_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Comando /queue - Status da fila de produÃ§Ã£o"""
    user_id = update.effective_user.id

    if not pipeline.is_authorized(user_id):
        await update.message.reply_text("âŒ UsuÃ¡rio nÃ£o autorizado")
        return

    try:
        # Analisar fila de pendentes
        pendentes_files = [
            f for f in os.listdir(POSTS_PENDENTES_DIR) if f.endswith(".html")
        ]
        enviados_files = [
            f for f in os.listdir(POSTS_ENVIADOS_DIR) if f.endswith(".html")
        ]

        # PrÃ³ximos 3 na fila
        next_in_queue = sorted(pendentes_files)[:3]

        # Ãšltimos 3 enviados
        last_sent = sorted(enviados_files, reverse=True)[:3]

        queue_msg = f"""
ğŸ“Š **Status da Fila de ProduÃ§Ã£o:**

ğŸ“‚ **Pendentes: {len(pendentes_files)} arquivos**
"""

        if next_in_queue:
            queue_msg += "\nğŸ”„ **PrÃ³ximos na fila:**\n"
            for i, file in enumerate(next_in_queue, 1):
                timestamp = file.split("_")[0]
                title = file.split("_", 1)[1].replace(".html", "").replace("-", " ")
                queue_msg += f"{i}. `{timestamp}` - {title[:30]}...\n"
        else:
            queue_msg += "\nâœ… Fila vazia\n"

        queue_msg += f"\nğŸ“¤ **Enviados: {len(enviados_files)} arquivos**"

        if last_sent:
            queue_msg += "\nğŸ‰ **Ãšltimos enviados:**\n"
            for file in last_sent:
                timestamp = file.split("_")[0]
                title = file.split("_", 1)[1].replace(".html", "").replace("-", " ")
                queue_msg += f"â€¢ `{timestamp}` - {title[:30]}...\n"

        # Log atual
        today_log = datetime.now().strftime("%Y-%m-%d.log")
        queue_msg += f"\nğŸ“ **Log atual:** `{today_log}`"

        await update.message.reply_text(queue_msg, parse_mode="Markdown")

    except Exception as e:
        await update.message.reply_text(f"âŒ Erro ao verificar fila: {e}")


async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Comando /status com validaÃ§Ãµes expandidas"""
    user_id = update.effective_user.id

    if not pipeline.is_authorized(user_id):
        await update.message.reply_text("âŒ UsuÃ¡rio nÃ£o autorizado")
        return

    # Verificar status dos componentes
    status_msg = "ğŸ“Š **Status do Sistema v2.6.0:**\n\n"

    # Verificar OpenAI
    if os.getenv("OPENAI_API_KEY"):
        status_msg += "âœ… OpenAI API configurada\n"
    else:
        status_msg += "âŒ OpenAI API nÃ£o configurada\n"

    # Verificar LinkedIn
    if os.getenv("LINKEDIN_EMAIL") and os.getenv("LINKEDIN_PASSWORD"):
        status_msg += "âœ… LinkedIn configurado\n"
    else:
        status_msg += "âŒ LinkedIn nÃ£o configurado\n"

    # Verificar diretÃ³rios de produÃ§Ã£o
    pendentes = len([f for f in os.listdir(POSTS_PENDENTES_DIR) if f.endswith(".html")])
    enviados = len([f for f in os.listdir(POSTS_ENVIADOS_DIR) if f.endswith(".html")])
    logs_count = len([f for f in os.listdir(POSTS_LOGS_DIR) if f.endswith(".log")])

    status_msg += f"ğŸ“‚ Pendentes: {pendentes}\n"
    status_msg += f"ğŸ“¤ Enviados: {enviados}\n"
    status_msg += f"ğŸ“ Logs diÃ¡rios: {logs_count}\n"

    # Verificar horÃ¡rio atual
    time_check = pipeline.validate_posting_time()
    if time_check["warnings"]:
        status_msg += f"âš ï¸ {time_check['warnings'][0]}\n"
    if time_check["recommendations"]:
        status_msg += f"ğŸ’¡ {time_check['recommendations'][0]}\n"

    await update.message.reply_text(status_msg, parse_mode="Markdown")


async def stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Comando /stats - EstatÃ­sticas avanÃ§adas com metadata"""
    user_id = update.effective_user.id

    if not pipeline.is_authorized(user_id):
        await update.message.reply_text("âŒ UsuÃ¡rio nÃ£o autorizado")
        return

    try:
        # Analisar arquivos metadata nas duas filas
        pendentes_metadata = [
            f for f in os.listdir(POSTS_PENDENTES_DIR) if f.endswith(".metadata.json")
        ]
        enviados_metadata = [
            f for f in os.listdir(POSTS_ENVIADOS_DIR) if f.endswith(".metadata.json")
        ]

        published_count = 0
        error_count = 0
        processing_count = 0
        pendente_count = 0

        # Analisar pendentes
        for meta_file in pendentes_metadata:
            try:
                with open(os.path.join(POSTS_PENDENTES_DIR, meta_file), "r") as f:
                    meta = json.load(f)

                status = meta.get("processing", {}).get("status", "unknown")
                if status == "pendente":
                    pendente_count += 1
                elif status == "processando":
                    processing_count += 1
                elif status == "erro":
                    error_count += 1
            except:
                continue

        # Analisar enviados
        for meta_file in enviados_metadata:
            try:
                with open(os.path.join(POSTS_ENVIADOS_DIR, meta_file), "r") as f:
                    meta = json.load(f)

                status = meta.get("processing", {}).get("status", "unknown")
                if status in ["publicado", "enviado"]:
                    published_count += 1
            except:
                continue

        # Ler estatÃ­sticas do CSV se existir
        csv_stats = ""
        csv_file = observability.csv_log_file
        if os.path.exists(csv_file):
            with open(csv_file, "r") as f:
                lines = f.readlines()

            total_records = len(lines) - 1  # -1 para header
            telegram_pipelines = len([l for l in lines if "telegram_start" in l])
            successes = len([l for l in lines if ",True," in l])
            failures = len([l for l in lines if ",False," in l])
            success_rate = (
                (successes * 100) // total_records if total_records > 0 else 0
            )

            csv_stats = f"""
ğŸ“ˆ **CSV Audit:**
â€¢ Total registros: {total_records}
â€¢ Pipelines Telegram: {telegram_pipelines}
â€¢ Sucessos: {successes}
â€¢ Falhas: {failures}
â€¢ Taxa de sucesso: {success_rate}%
"""

        stats_msg = f"""
ğŸ“Š **EstatÃ­sticas AvanÃ§adas v2.6.0:**
{csv_stats}
ğŸ“‹ **Sistema de Filas:**
â€¢ ğŸ“‚ Pendentes: {pendente_count}
â€¢ ğŸ”„ Processando: {processing_count}
â€¢ ğŸ“¤ Publicados: {published_count}
â€¢ âŒ Erros: {error_count}

ğŸ“ **Logs por Data:**
â€¢ Log atual: `{datetime.now().strftime('%Y-%m-%d.log')}`
â€¢ Total logs: {len([f for f in os.listdir(POSTS_LOGS_DIR) if f.endswith('.log')])}

â° **HorÃ¡rio atual:** {datetime.now().strftime('%H:%M - %A')}

Para detalhes completos:
`./monitor_logs.sh`
"""

        await update.message.reply_text(stats_msg, parse_mode="Markdown")

    except Exception as e:
        await update.message.reply_text(f"âŒ Erro ao obter estatÃ­sticas: {e}")


async def approve_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Comando /approve - Aprovar conteÃºdo para publicaÃ§Ã£o"""
    user_id = update.effective_user.id

    if not pipeline.is_authorized(user_id):
        await update.message.reply_text("âŒ UsuÃ¡rio nÃ£o autorizado")
        return

    if user_id not in pipeline.pending_approvals:
        await update.message.reply_text("âŒ Nenhum conteÃºdo aguardando aprovaÃ§Ã£o")
        return

    processing_msg = await update.message.reply_text(
        "âœ… Aprovado! Publicando no LinkedIn..."
    )

    try:
        # Publicar conteÃºdo aprovado
        result = await pipeline.publish_approved_content(user_id)

        if result["status"] == "published":
            success_msg = f"""
âœ… **PUBLICADO COM SUCESSO!**

ğŸ†” **ID:** `{result["execution_id"]}`
â±ï¸ **Tempo:** {result["duration_ms"]}ms
ğŸ“¤ **Status:** Movido para enviados
ğŸ”— **LinkedIn:** Post publicado!

ğŸ“ **Log:** `{datetime.now().strftime('%Y-%m-%d.log')}`
"""
            await processing_msg.edit_text(success_msg, parse_mode="Markdown")
        else:
            error_msg = f"""
âŒ **Erro na publicaÃ§Ã£o**

ğŸ†” **ID:** `{result["execution_id"]}`
ğŸš¨ **Erro:** {result["error"]}
â±ï¸ **Tempo:** {result["duration_ms"]}ms

O conteÃºdo permanece aguardando aprovaÃ§Ã£o.
Use /retry para tentar novamente.
"""
            await processing_msg.edit_text(error_msg, parse_mode="Markdown")

    except Exception as e:
        await processing_msg.edit_text(f"âŒ Erro inesperado na aprovaÃ§Ã£o: {e}")


async def cancel_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Comando /cancel - Cancelar conteÃºdo pendente"""
    user_id = update.effective_user.id

    if not pipeline.is_authorized(user_id):
        await update.message.reply_text("âŒ UsuÃ¡rio nÃ£o autorizado")
        return

    if user_id not in pipeline.pending_approvals:
        await update.message.reply_text("âŒ Nenhum conteÃºdo aguardando aprovaÃ§Ã£o")
        return

    # Pegar dados da aprovaÃ§Ã£o
    approval_data = pipeline.pending_approvals[user_id]
    execution_id = approval_data["execution_id"]
    file_path = approval_data["file_path"]
    metadata_path = approval_data["metadata_path"]

    # Atualizar metadata como cancelado
    try:
        if os.path.exists(metadata_path):
            with open(metadata_path, "r") as f:
                meta = json.load(f)
            meta["processing"]["status"] = "cancelado"
            meta["processing"]["cancelled_at"] = datetime.now().isoformat()
            with open(metadata_path, "w") as f:
                json.dump(meta, f, indent=2)

        # Remover da lista de aprovaÃ§Ãµes
        del pipeline.pending_approvals[user_id]

        # Log do cancelamento
        pipeline.pipeline_logger.info(
            f"ğŸš« ConteÃºdo cancelado pelo usuÃ¡rio: {execution_id}"
        )

        await update.message.reply_text(
            f"""
ğŸš« **ConteÃºdo cancelado**

ğŸ†” **ID:** `{execution_id}`
ğŸ“ **Status:** Cancelado (mantido em pendentes)
ğŸ“ **Log:** `{datetime.now().strftime('%Y-%m-%d.log')}`

VocÃª pode enviar um novo arquivo quando desejar.
""",
            parse_mode="Markdown",
        )

    except Exception as e:
        await update.message.reply_text(f"âŒ Erro ao cancelar: {e}")


async def pending_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Comando /pending - Ver conteÃºdo aguardando aprovaÃ§Ã£o"""
    user_id = update.effective_user.id

    if not pipeline.is_authorized(user_id):
        await update.message.reply_text("âŒ UsuÃ¡rio nÃ£o autorizado")
        return

    if user_id not in pipeline.pending_approvals:
        await update.message.reply_text("âœ… Nenhum conteÃºdo aguardando aprovaÃ§Ã£o")
        return

    # Mostrar conteÃºdo pendente
    approval_data = pipeline.pending_approvals[user_id]
    review = approval_data["review"]
    content = approval_data["processed_content"]

    # Formatar para Telegram
    review_message = pipeline.reviewer.format_review_for_telegram(review, content)

    await update.message.reply_text(review_message, parse_mode="Markdown")


async def retry_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Comando /retry - Tentar publicar novamente"""
    user_id = update.effective_user.id

    if not pipeline.is_authorized(user_id):
        await update.message.reply_text("âŒ UsuÃ¡rio nÃ£o autorizado")
        return

    if user_id not in pipeline.pending_approvals:
        await update.message.reply_text("âŒ Nenhum conteÃºdo aguardando aprovaÃ§Ã£o")
        return

    processing_msg = await update.message.reply_text(
        "ğŸ”„ Tentando publicar novamente..."
    )

    try:
        result = await pipeline.publish_approved_content(user_id)

        if result["status"] == "published":
            success_msg = f"""
âœ… **PUBLICADO COM SUCESSO!** (retry)

ğŸ†” **ID:** `{result["execution_id"]}`
â±ï¸ **Tempo:** {result["duration_ms"]}ms
ğŸ“¤ **Status:** Movido para enviados
ğŸ”— **LinkedIn:** Post publicado!
"""
            await processing_msg.edit_text(success_msg, parse_mode="Markdown")
        else:
            error_msg = f"""
âŒ **Retry falhou**

ğŸš¨ **Erro:** {result["error"]}
â±ï¸ **Tempo:** {result["duration_ms"]}ms

Use /cancel para desistir ou /retry para tentar novamente.
"""
            await processing_msg.edit_text(error_msg, parse_mode="Markdown")

    except Exception as e:
        await processing_msg.edit_text(f"âŒ Erro no retry: {e}")


async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Processar arquivo recebido com sistema de filas e revisÃ£o"""
    user_id = update.effective_user.id

    if not pipeline.is_authorized(user_id):
        await update.message.reply_text("âŒ UsuÃ¡rio nÃ£o autorizado")
        return

    # Verificar se jÃ¡ tem conteÃºdo aguardando aprovaÃ§Ã£o
    if user_id in pipeline.pending_approvals:
        await update.message.reply_text(
            """
âš ï¸ **VocÃª tem conteÃºdo aguardando aprovaÃ§Ã£o**

Use um destes comandos primeiro:
â€¢ /pending - Ver conteÃºdo aguardando
â€¢ /approve - Aprovar e publicar
â€¢ /cancel - Cancelar conteÃºdo atual

Depois envie o novo arquivo.
""",
            parse_mode="Markdown",
        )
        return

    document = update.message.document

    # Verificar se Ã© arquivo HTML
    if not document.file_name or not document.file_name.lower().endswith(".html"):
        await update.message.reply_text(
            "âŒ Por favor, envie apenas arquivos HTML (.html)"
        )
        return

    # Verificar tamanho do arquivo (limite: 10MB)
    if document.file_size > 10 * 1024 * 1024:  # 10MB
        await update.message.reply_text("âŒ Arquivo muito grande. MÃ¡ximo: 10MB")
        return

    # Enviar confirmaÃ§Ã£o de recebimento
    processing_msg = await update.message.reply_text(
        f"ğŸ“¥ Recebido: `{document.file_name}`\nğŸ”„ Adicionando Ã  fila de pendentes..."
    )

    try:
        # 1. Baixar e validar arquivo (adiciona Ã  fila de pendentes)
        result = await pipeline.download_and_validate_file(document, context, user_id)

        if result["status"] == "invalid":
            validation = result["validation"]
            error_msg = f"""
âŒ **Arquivo invÃ¡lido**

**Problemas encontrados:**
{chr(10).join([f"â€¢ {issue}" for issue in validation["issues"]])}

**Avisos:**
{chr(10).join([f"â€¢ {warning}" for warning in validation.get("warnings", [])])}

Por favor, envie um arquivo HTML vÃ¡lido.
"""
            await processing_msg.edit_text(error_msg, parse_mode="Markdown")
            return

        if result["status"] == "error":
            await processing_msg.edit_text(
                f"âŒ Erro ao processar arquivo: {result['error']}"
            )
            return

        # 2. Mostrar status da fila
        metadata = result["metadata"]
        time_check = pipeline.validate_posting_time()

        queue_msg = f"""
âœ… **Arquivo adicionado Ã  fila!**

ğŸ“‚ **Arquivo:** `{result['filename']}`
ğŸ“ **TÃ­tulo:** {metadata.get('title', 'N/A')}
ğŸ“Š **Palavras:** {metadata.get('word_count', 0)}
ğŸ“ **Caracteres:** {metadata.get('char_count', 0)}
ğŸ·ï¸ **PosiÃ§Ã£o na fila:** {result.get('queue_position', 'N/A')}

ğŸ“‚ **Status:** PENDENTE âœ processando âœ enviados
"""

        if time_check["warnings"]:
            queue_msg += f"\nâš ï¸ {time_check['warnings'][0]}"
        if time_check["recommendations"]:
            queue_msg += f"\nğŸ’¡ {time_check['recommendations'][0]}"

        queue_msg += "\n\nğŸ¤– Iniciando processamento com revisÃ£o..."

        await processing_msg.edit_text(queue_msg, parse_mode="Markdown")

        # 3. Executar pipeline com revisÃ£o
        pipeline_result = await pipeline.process_pipeline_with_review(
            result["file_path"], user_id, metadata
        )

        if pipeline_result["status"] == "awaiting_approval":
            review = pipeline_result["review"]

            # Formatar review para Telegram
            review_message = pipeline.reviewer.format_review_for_telegram(
                review, pipeline_result["processed_content"]
            )

            final_msg = f"""
âœ… **Processamento completo - AGUARDANDO APROVAÃ‡ÃƒO**

ğŸ†” **ID:** `{pipeline_result["execution_id"]}`
â±ï¸ **Tempo:** {pipeline_result["duration_ms"]}ms
ğŸ“ **Status:** pendentes â†’ aguardando aprovaÃ§Ã£o

{review_message}
"""
            await processing_msg.edit_text(final_msg, parse_mode="Markdown")

        else:
            error_msg = f"""
âŒ **Erro no pipeline**

ğŸ†” **ID:** `{pipeline_result["execution_id"]}`
â±ï¸ **Tempo:** {pipeline_result["duration_ms"]}ms
ğŸš¨ **Erro:** {pipeline_result["error"]}

ğŸ“ **Status:** Mantido em **pendentes** para retry
"""
            await processing_msg.edit_text(error_msg, parse_mode="Markdown")

    except Exception as e:
        pipeline.pipeline_logger.error(f"âŒ Erro no handler de documento: {e}")
        await processing_msg.edit_text(f"âŒ Erro inesperado: {e}")


async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Processar mensagem de texto"""
    user_id = update.effective_user.id

    if not pipeline.is_authorized(user_id):
        return

    await update.message.reply_text(
        "ğŸ“„ Por favor, envie um arquivo HTML para adicionar Ã  fila.\n"
        "Use /queue para ver o status da fila ou /start para instruÃ§Ãµes."
    )


def main():
    """FunÃ§Ã£o principal do bot"""
    if not TELEGRAM_BOT_TOKEN:
        logger.error("âŒ TELEGRAM_BOT_TOKEN nÃ£o configurado")
        return

    logger.info("ğŸš€ Iniciando Telegram Bot v2.6.1 com RevisÃ£o de ConteÃºdo...")

    # Criar aplicaÃ§Ã£o
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    # Registrar handlers
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("status", status_command))
    application.add_handler(CommandHandler("stats", stats_command))
    application.add_handler(CommandHandler("queue", queue_command))
    application.add_handler(CommandHandler("approve", approve_command))
    application.add_handler(CommandHandler("cancel", cancel_command))
    application.add_handler(CommandHandler("pending", pending_command))
    application.add_handler(CommandHandler("retry", retry_command))
    application.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    application.add_handler(
        MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text)
    )

    logger.info("âœ… Telegram Bot v2.6.1 iniciado com Sistema de RevisÃ£o")
    logger.info(
        "ğŸ“‹ Comandos de aprovaÃ§Ã£o disponÃ­veis: /approve, /cancel, /pending, /retry"
    )

    # Executar bot
    application.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    main()
