#!/usr/bin/env python3
"""
Telegram Bot para receber arquivos HTML e iniciar pipeline de processamento
Sistema completo com validaÃ§Ãµes, metadata.json e arquivos padronizados
"""
import os
import json
import logging
import asyncio
from datetime import datetime, time
from pathlib import Path
from typing import Optional, Dict, Tuple

from dotenv import load_dotenv
import requests
from telegram import Update, Document
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    filters,
    ContextTypes,
)

# Importar mÃ³dulos do projeto
from .post_processor import PostProcessor
from .html_parser import HTMLParser, validate_html_file
from .linkedin_poster import observability, logger

# Carregar configuraÃ§Ãµes
load_dotenv()

# ConfiguraÃ§Ãµes do bot
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")
POSTS_DIR = "posts"

# Configurar diretÃ³rio de posts
os.makedirs(POSTS_DIR, exist_ok=True)


class TelegramPipeline:
    """Gerenciador do pipeline Telegram â†’ GPT â†’ LinkedIn com validaÃ§Ãµes avanÃ§adas"""

    def __init__(self):
        self.processor = PostProcessor()
        self.html_parser = HTMLParser()
        self.authorized_users = self._get_authorized_users()

    def _get_authorized_users(self) -> list:
        """Obter lista de usuÃ¡rios autorizados"""
        authorized = os.getenv("TELEGRAM_AUTHORIZED_USERS", "")
        if authorized:
            return [int(uid.strip()) for uid in authorized.split(",")]
        return []

    def is_authorized(self, user_id: int) -> bool:
        """Verificar se usuÃ¡rio estÃ¡ autorizado"""
        if not self.authorized_users:
            return True  # Se nÃ£o configurado, permite todos
        return user_id in self.authorized_users

    def validate_posting_time(self) -> Dict:
        """Validar se Ã© um horÃ¡rio apropriado para posting"""
        now = datetime.now()
        current_time = now.time()
        current_day = now.weekday()  # 0=segunda, 6=domingo

        validation = {"valid": True, "warnings": [], "recommendations": []}

        # HorÃ¡rios recomendados para LinkedIn (8h-18h dias Ãºteis)
        business_start = time(8, 0)  # 08:00
        business_end = time(18, 0)  # 18:00

        # Verificar se Ã© dia Ãºtil (segunda a sexta)
        if current_day >= 5:  # sÃ¡bado ou domingo
            validation["warnings"].append(
                f"ğŸ“… Final de semana - menor engajamento esperado"
            )
            validation["recommendations"].append(
                "Considere agendar para segunda-feira 8h-10h"
            )

        # Verificar horÃ¡rio
        if current_time < business_start:
            validation["warnings"].append(
                f"ğŸ• Muito cedo ({now.strftime('%H:%M')}) - audiÃªncia ainda nÃ£o ativa"
            )
            validation["recommendations"].append("HorÃ¡rio ideal: 8h-10h ou 17h-19h")
        elif current_time > business_end:
            validation["warnings"].append(
                f"ğŸ• HorÃ¡rio tardio ({now.strftime('%H:%M')}) - menor visibilidade"
            )
            validation["recommendations"].append(
                "Considere postar entre 8h-18h nos dias Ãºteis"
            )
        else:
            validation["recommendations"].append(
                f"âœ… Bom horÃ¡rio para posting ({now.strftime('%H:%M')})"
            )

        return validation

    def create_standardized_filename(
        self, document: Document, metadata: Dict
    ) -> Tuple[str, str]:
        """Criar nome de arquivo padronizado: timestamp_slug-titulo.html"""

        # Timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # Slug do tÃ­tulo
        title = metadata.get("title", "")
        if not title and document.file_name:
            # Usar nome do arquivo original como fallback
            title = Path(document.file_name).stem

        slug = self.html_parser.create_slug(title) if title else "sem_titulo"

        # Nome final padronizado
        filename = f"{timestamp}_{slug}.html"
        filepath = os.path.join(POSTS_DIR, filename)

        # Garantir que nÃ£o existe conflito
        counter = 1
        while os.path.exists(filepath):
            filename = f"{timestamp}_{slug}_{counter}.html"
            filepath = os.path.join(POSTS_DIR, filename)
            counter += 1

        return filepath, filename

    def save_metadata(
        self, filepath: str, metadata: Dict, document: Document, user_id: int
    ) -> str:
        """Salvar metadata.json junto com o arquivo HTML"""

        # Criar metadata expandido
        full_metadata = {
            **metadata,
            "telegram": {
                "user_id": user_id,
                "file_name": document.file_name,
                "file_size": document.file_size,
                "mime_type": document.mime_type,
                "received_at": datetime.now().isoformat(),
            },
            "processing": {
                "status": "received",
                "pipeline_id": None,
                "processed_at": None,
                "published_at": None,
            },
            "validation": {
                "html_valid": metadata.get("valid", False),
                "time_check": self.validate_posting_time(),
            },
        }

        # Caminho do metadata
        metadata_path = filepath.replace(".html", ".metadata.json")

        try:
            with open(metadata_path, "w", encoding="utf-8") as f:
                json.dump(full_metadata, f, indent=2, ensure_ascii=False)

            logger.info(f"ğŸ“‹ Metadata salvo: {metadata_path}")
            return metadata_path

        except Exception as e:
            logger.error(f"âŒ Erro ao salvar metadata: {e}")
            return ""

    async def download_and_validate_file(
        self, document: Document, context: ContextTypes.DEFAULT_TYPE, user_id: int
    ) -> Optional[Dict]:
        """Baixar arquivo e fazer validaÃ§Ã£o completa"""
        try:
            # 1. Baixar arquivo temporÃ¡rio primeiro
            temp_path = (
                f"{POSTS_DIR}/temp_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            )

            file = await document.get_file()
            await file.download_to_drive(temp_path)

            logger.info(f"ğŸ“¥ Arquivo temporÃ¡rio baixado: {temp_path}")

            # 2. Validar conteÃºdo HTML
            validation = validate_html_file(temp_path)

            if not validation["valid"]:
                # Remover arquivo temporÃ¡rio se invÃ¡lido
                os.remove(temp_path)
                return {"status": "invalid", "validation": validation}

            # 3. Extrair metadados
            metadata = self.html_parser.extract_metadata(temp_path)
            metadata.update(validation)  # Incluir dados de validaÃ§Ã£o

            # 4. Criar nome de arquivo padronizado
            final_path, filename = self.create_standardized_filename(document, metadata)

            # 5. Mover arquivo para nome final
            os.rename(temp_path, final_path)

            # 6. Salvar metadata.json
            metadata_path = self.save_metadata(final_path, metadata, document, user_id)

            logger.info(f"âœ… Arquivo processado: {filename}")

            return {
                "status": "success",
                "file_path": final_path,
                "filename": filename,
                "metadata_path": metadata_path,
                "metadata": metadata,
                "validation": validation,
            }

        except Exception as e:
            # Limpar arquivo temporÃ¡rio se existir
            if "temp_path" in locals() and os.path.exists(temp_path):
                os.remove(temp_path)

            logger.error(f"âŒ Erro ao processar arquivo: {e}")
            return {"status": "error", "error": str(e)}

    async def process_pipeline(
        self, file_path: str, user_id: int, metadata: Dict
    ) -> dict:
        """Executar pipeline completo com metadata tracking"""
        execution_id = f"tg_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{user_id}"
        start_time = datetime.now()

        try:
            # Log inÃ­cio do pipeline
            observability.log_csv_event(
                execution_id,
                "telegram_start",
                True,
                "",
                f"file://{file_path}",
                "",
                "",
                "",
                0,
            )

            # 1. Atualizar metadata de status
            metadata_path = file_path.replace(".html", ".metadata.json")
            if os.path.exists(metadata_path):
                with open(metadata_path, "r") as f:
                    meta = json.load(f)
                meta["processing"]["status"] = "processing"
                meta["processing"]["pipeline_id"] = execution_id
                with open(metadata_path, "w") as f:
                    json.dump(meta, f, indent=2)

            # 2. Processar com GPT
            logger.info("ğŸ¤– Processando conteÃºdo com GPT-4o-mini...")
            processed_content = await self.processor.process_html_file(file_path)

            if not processed_content:
                raise Exception("Falha no processamento GPT")

            # Log processamento GPT
            processing_time = int((datetime.now() - start_time).total_seconds() * 1000)
            observability.log_csv_event(
                execution_id,
                "gpt_processing",
                True,
                processed_content[:100],
                f"file://{file_path}",
                "",
                "",
                "",
                processing_time,
            )

            # 3. Publicar no LinkedIn
            logger.info("ğŸ”— Publicando no LinkedIn...")
            from .linkedin_poster import get_driver, login, publish_post

            driver = None
            try:
                driver = get_driver()
                login(driver, execution_id)
                publish_post(driver, processed_content, execution_id)

                # 4. Atualizar metadata final
                if os.path.exists(metadata_path):
                    with open(metadata_path, "r") as f:
                        meta = json.load(f)
                    meta["processing"]["status"] = "published"
                    meta["processing"]["processed_at"] = datetime.now().isoformat()
                    meta["processing"]["published_at"] = datetime.now().isoformat()
                    meta["processing"]["final_content"] = processed_content
                    with open(metadata_path, "w") as f:
                        json.dump(meta, f, indent=2)

                # Log sucesso total
                total_time = int((datetime.now() - start_time).total_seconds() * 1000)
                observability.log_csv_event(
                    execution_id,
                    "pipeline_complete",
                    True,
                    processed_content,
                    "https://linkedin.com/feed/",
                    "",
                    "",
                    "",
                    total_time,
                )

                return {
                    "status": "success",
                    "execution_id": execution_id,
                    "processed_content": processed_content,
                    "duration_ms": total_time,
                    "title": metadata.get("title", "N/A"),
                    "word_count": metadata.get("word_count", 0),
                }

            finally:
                if driver:
                    driver.quit()

        except Exception as e:
            # Log erro no pipeline
            error_time = int((datetime.now() - start_time).total_seconds() * 1000)
            observability.log_csv_event(
                execution_id,
                "pipeline_error",
                False,
                "",
                f"file://{file_path}",
                type(e).__name__,
                str(e),
                "",
                error_time,
            )

            # Atualizar metadata com erro
            metadata_path = file_path.replace(".html", ".metadata.json")
            if os.path.exists(metadata_path):
                with open(metadata_path, "r") as f:
                    meta = json.load(f)
                meta["processing"]["status"] = "error"
                meta["processing"]["error"] = str(e)
                meta["processing"]["error_at"] = datetime.now().isoformat()
                with open(metadata_path, "w") as f:
                    json.dump(meta, f, indent=2)

            # Enviar alerta
            observability.send_alert(
                "Erro no Pipeline Telegram", str(e), f"file://{file_path}"
            )

            return {
                "status": "error",
                "execution_id": execution_id,
                "error": str(e),
                "duration_ms": error_time,
            }


# InstÃ¢ncia global do pipeline
pipeline = TelegramPipeline()


async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Comando /start"""
    user_id = update.effective_user.id

    if not pipeline.is_authorized(user_id):
        await update.message.reply_text("âŒ UsuÃ¡rio nÃ£o autorizado")
        return

    # Verificar horÃ¡rio atual
    time_check = pipeline.validate_posting_time()
    time_info = ""
    if time_check["warnings"]:
        time_info = f"\nâš ï¸ {time_check['warnings'][0]}"
    if time_check["recommendations"]:
        time_info += f"\nğŸ’¡ {time_check['recommendations'][0]}"

    message = f"""
ğŸš€ **LinkedIn Content Pipeline Bot v2.5.1**

Envie um arquivo HTML e eu vou:
1. ğŸ“¥ Baixar e validar o arquivo
2. ğŸ“‹ Extrair metadados (tÃ­tulo, descriÃ§Ã£o, etc.)
3. ğŸ¤– Processar com GPT-4o-mini
4. ğŸ”— Publicar no LinkedIn
5. ğŸ’¾ Salvar metadata.json completo

**ValidaÃ§Ãµes automÃ¡ticas:**
âœ… ConteÃºdo HTML vÃ¡lido
âœ… Tamanho adequado (50+ chars)
âœ… Estrutura de arquivo padronizada
âœ… HorÃ¡rio de posting otimizado

**Arquivos salvos:**
ğŸ“ `YYYYMMDD_HHMMSS_slug-titulo.html`
ğŸ“‹ `YYYYMMDD_HHMMSS_slug-titulo.metadata.json`

**Comandos:**
/start - Mostrar esta mensagem
/status - Ver status do sistema  
/stats - EstatÃ­sticas de uso
{time_info}
"""

    await update.message.reply_text(message, parse_mode="Markdown")


async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Comando /status com validaÃ§Ãµes expandidas"""
    user_id = update.effective_user.id

    if not pipeline.is_authorized(user_id):
        await update.message.reply_text("âŒ UsuÃ¡rio nÃ£o autorizado")
        return

    # Verificar status dos componentes
    status_msg = "ğŸ“Š **Status do Sistema v2.5.1:**\n\n"

    # Verificar OpenAI
    if os.getenv("OPENAI_API_KEY"):
        status_msg += "âœ… OpenAI API configurada\n"
    else:
        status_msg += "âŒ OpenAI API nÃ£o configurada\n"

    # Verificar LinkedIn
    if os.getenv("LINKEDIN_EMAIL") and os.getenv("LINKEDIN_PASSWORD"):
        status_msg += "âœ… LinkedIn configurado\n"
    else:
        status_msg += "âŒ LinkedIn nÃ£o configurado\n"

    # Verificar diretÃ³rio posts
    html_files = len([f for f in os.listdir(POSTS_DIR) if f.endswith(".html")])
    json_files = len([f for f in os.listdir(POSTS_DIR) if f.endswith(".metadata.json")])
    status_msg += f"ğŸ“ Arquivos HTML: {html_files}\n"
    status_msg += f"ğŸ“‹ Arquivos metadata: {json_files}\n"

    # Verificar horÃ¡rio atual
    time_check = pipeline.validate_posting_time()
    if time_check["warnings"]:
        status_msg += f"âš ï¸ {time_check['warnings'][0]}\n"
    if time_check["recommendations"]:
        status_msg += f"ğŸ’¡ {time_check['recommendations'][0]}\n"

    await update.message.reply_text(status_msg, parse_mode="Markdown")


async def stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Comando /stats - EstatÃ­sticas avanÃ§adas com metadata"""
    user_id = update.effective_user.id

    if not pipeline.is_authorized(user_id):
        await update.message.reply_text("âŒ UsuÃ¡rio nÃ£o autorizado")
        return

    try:
        # Ler estatÃ­sticas do CSV
        csv_file = observability.csv_log_file

        if not os.path.exists(csv_file):
            await update.message.reply_text("ğŸ“Š Nenhuma estatÃ­stica disponÃ­vel ainda")
            return

        # Analisar arquivos metadata
        metadata_files = [
            f for f in os.listdir(POSTS_DIR) if f.endswith(".metadata.json")
        ]

        published_count = 0
        error_count = 0
        processing_count = 0

        for meta_file in metadata_files:
            try:
                with open(os.path.join(POSTS_DIR, meta_file), "r") as f:
                    meta = json.load(f)

                status = meta.get("processing", {}).get("status", "unknown")
                if status == "published":
                    published_count += 1
                elif status == "error":
                    error_count += 1
                elif status == "processing":
                    processing_count += 1
            except:
                continue

        # Contar registros CSV
        with open(csv_file, "r") as f:
            lines = f.readlines()

        total_records = len(lines) - 1  # -1 para header
        telegram_pipelines = len([l for l in lines if "telegram_start" in l])
        successes = len([l for l in lines if ",True," in l])
        failures = len([l for l in lines if ",False," in l])

        success_rate = (successes * 100) // total_records if total_records > 0 else 0

        stats_msg = f"""
ğŸ“Š **EstatÃ­sticas AvanÃ§adas v2.5.1:**

ğŸ“ˆ **CSV Audit:**
â€¢ Total registros: {total_records}
â€¢ Pipelines Telegram: {telegram_pipelines}
â€¢ Sucessos: {successes}
â€¢ Falhas: {failures}
â€¢ Taxa de sucesso: {success_rate}%

ğŸ“‹ **Metadata Tracking:**
â€¢ Arquivos recebidos: {len(metadata_files)}
â€¢ Publicados com sucesso: {published_count}
â€¢ Erros de processamento: {error_count}
â€¢ Em processamento: {processing_count}

â° **HorÃ¡rio atual:** {datetime.now().strftime('%H:%M - %A')}

Para detalhes completos:
`./monitor_logs.sh`
"""

        await update.message.reply_text(stats_msg, parse_mode="Markdown")

    except Exception as e:
        await update.message.reply_text(f"âŒ Erro ao obter estatÃ­sticas: {e}")


async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Processar arquivo recebido com validaÃ§Ãµes completas"""
    user_id = update.effective_user.id

    if not pipeline.is_authorized(user_id):
        await update.message.reply_text("âŒ UsuÃ¡rio nÃ£o autorizado")
        return

    document = update.message.document

    # Verificar se Ã© arquivo HTML
    if not document.file_name or not document.file_name.lower().endswith(".html"):
        await update.message.reply_text(
            "âŒ Por favor, envie apenas arquivos HTML (.html)"
        )
        return

    # Verificar tamanho do arquivo (limite: 10MB)
    if document.file_size > 10 * 1024 * 1024:  # 10MB
        await update.message.reply_text("âŒ Arquivo muito grande. MÃ¡ximo: 10MB")
        return

    # Enviar confirmaÃ§Ã£o de recebimento
    processing_msg = await update.message.reply_text(
        f"ğŸ“¥ Recebido: `{document.file_name}`\nğŸ”„ Validando e processando..."
    )

    try:
        # 1. Baixar e validar arquivo
        result = await pipeline.download_and_validate_file(document, context, user_id)

        if result["status"] == "invalid":
            validation = result["validation"]
            error_msg = f"""
âŒ **Arquivo invÃ¡lido**

**Problemas encontrados:**
{chr(10).join([f"â€¢ {issue}" for issue in validation["issues"]])}

**Avisos:**
{chr(10).join([f"â€¢ {warning}" for warning in validation.get("warnings", [])])}

Por favor, envie um arquivo HTML vÃ¡lido.
"""
            await processing_msg.edit_text(error_msg, parse_mode="Markdown")
            return

        if result["status"] == "error":
            await processing_msg.edit_text(
                f"âŒ Erro ao processar arquivo: {result['error']}"
            )
            return

        # 2. Mostrar validaÃ§Ãµes de horÃ¡rio
        metadata = result["metadata"]
        time_check = pipeline.validate_posting_time()

        validation_msg = f"""
âœ… **Arquivo validado com sucesso!**

ğŸ“„ **Arquivo:** `{result['filename']}`
ğŸ“ **TÃ­tulo:** {metadata.get('title', 'N/A')}
ğŸ“Š **Palavras:** {metadata.get('word_count', 0)}
ğŸ“ **Caracteres:** {metadata.get('char_count', 0)}

"""

        if time_check["warnings"]:
            validation_msg += f"âš ï¸ {time_check['warnings'][0]}\n"
        if time_check["recommendations"]:
            validation_msg += f"ğŸ’¡ {time_check['recommendations'][0]}\n"

        validation_msg += "\nğŸ¤– Processando com GPT-4o-mini..."

        await processing_msg.edit_text(validation_msg, parse_mode="Markdown")

        # 3. Executar pipeline
        pipeline_result = await pipeline.process_pipeline(
            result["file_path"], user_id, metadata
        )

        if pipeline_result["status"] == "success":
            success_msg = f"""
âœ… **Pipeline concluÃ­do com sucesso!**

ğŸ†” **ID:** `{pipeline_result["execution_id"]}`
ğŸ“ **TÃ­tulo:** {pipeline_result.get("title", "N/A")}
â±ï¸ **Tempo:** {pipeline_result["duration_ms"]}ms
ğŸ“Š **Palavras originais:** {pipeline_result.get("word_count", 0)}
ğŸ“ **ConteÃºdo final:** {len(pipeline_result["processed_content"])} chars

ğŸ“‹ **Arquivos salvos:**
â€¢ `{result['filename']}`
â€¢ `{result['filename'].replace('.html', '.metadata.json')}`

ğŸ”— **Post publicado no LinkedIn!**
"""
            await processing_msg.edit_text(success_msg, parse_mode="Markdown")

        else:
            error_msg = f"""
âŒ **Erro no pipeline**

ğŸ†” **ID:** `{pipeline_result["execution_id"]}`
â±ï¸ **Tempo:** {pipeline_result["duration_ms"]}ms
ğŸš¨ **Erro:** {pipeline_result["error"]}

ğŸ“‹ **Metadata salvo** com detalhes do erro.
Verifique os logs para mais informaÃ§Ãµes.
"""
            await processing_msg.edit_text(error_msg, parse_mode="Markdown")

    except Exception as e:
        logger.error(f"âŒ Erro no handler de documento: {e}")
        await processing_msg.edit_text(f"âŒ Erro inesperado: {e}")


async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Processar mensagem de texto"""
    user_id = update.effective_user.id

    if not pipeline.is_authorized(user_id):
        return

    await update.message.reply_text(
        "ğŸ“„ Por favor, envie um arquivo HTML para processar.\n"
        "Use /start para ver instruÃ§Ãµes completas."
    )


def main():
    """FunÃ§Ã£o principal do bot"""
    if not TELEGRAM_BOT_TOKEN:
        logger.error("âŒ TELEGRAM_BOT_TOKEN nÃ£o configurado")
        return

    logger.info("ğŸš€ Iniciando Telegram Bot v2.5.1...")

    # Criar aplicaÃ§Ã£o
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    # Registrar handlers
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("status", status_command))
    application.add_handler(CommandHandler("stats", stats_command))
    application.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    application.add_handler(
        MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text)
    )

    # Log inÃ­cio
    observability.log_csv_event(
        "telegram_bot", "bot_start", True, "", "", "", "", "", 0
    )

    logger.info("âœ… Telegram Bot v2.5.1 iniciado com sucesso")
    logger.info(f"ğŸ“ DiretÃ³rio de posts: {os.path.abspath(POSTS_DIR)}")
    logger.info("ğŸ“‹ Sistema de metadata.json ativo")
    logger.info("â° ValidaÃ§Ã£o de horÃ¡rio ativa")

    # Executar bot
    application.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    main()
